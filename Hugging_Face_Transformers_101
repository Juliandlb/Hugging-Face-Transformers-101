{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hugging Face Transformers 101\n\nThe objective of this notebook is to give an extensive summary on how to use the [transformers](https://github.com/huggingface/transformers) library from [Hugging Face](https://huggingface.co/).\n\n**Useful links:**\n- [Hugging Face - Model Hub](https://huggingface.co/models)\n- [Hugging Face - Datasets](https://huggingface.co/datasets)\n","metadata":{}},{"cell_type":"markdown","source":"# Pipelines\n\nThe [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines) is the easiest and fastest way to use a pretrained model for inference. In this case the pipeline downloads and caches a default pretrained model and tokenizer for sentiment analysis\n\n| **Task**                     | **Description**                                                                                              | **Modality**    | **Pipeline identifier**                       |\n|------------------------------|--------------------------------------------------------------------------------------------------------------|-----------------|-----------------------------------------------|\n| Text classification          | assign a label to a given sequence of text                                                                   | NLP             | pipeline(task=“sentiment-analysis”)           |\n| Text generation              | generate text given a prompt                                                                                 | NLP             | pipeline(task=“text-generation”)              |\n| Summarization                | generate a summary of a sequence of text or document                                                         | NLP             | pipeline(task=“summarization”)                |\n| Image classification         | assign a label to an image                                                                                   | Computer vision | pipeline(task=“image-classification”)         |\n| Image segmentation           | assign a label to each individual pixel of an image (supports semantic, panoptic, and instance segmentation) | Computer vision | pipeline(task=“image-segmentation”)           |\n| Object detection             | predict the bounding boxes and classes of objects in an image                                                | Computer vision | pipeline(task=“object-detection”)             |\n| Audio classification         | assign a label to some audio data                                                                            | Audio           | pipeline(task=“audio-classification”)         |\n| Automatic speech recognition | transcribe speech into text                                                                                  | Audio           | pipeline(task=“automatic-speech-recognition”) |\n| Visual question answering    | answer a question about the image, given an image and a question                                             | Multimodal      | pipeline(task=“vqa”)                          |\n| Document question answering  | answer a question about a document, given an image and a question                                            | Multimodal      | pipeline(task=\"document-question-answering\")  |\n| Image captioning             | generate a caption for a given image                                                                         | Multimodal      | pipeline(task=\"image-to-text\")                |\n","metadata":{}},{"cell_type":"markdown","source":"1 - `sentiment-analysis` - Vector as an Input","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# We can create a vector of data for the classifier\nclassifier = pipeline(\"sentiment-analysis\")\nprompts = [\"This is a very happy example :).\",\n           \"We hope you don't hate it.\"]\nresults = classifier(prompts)\nfor result in results:\n    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:55:41.012563Z","iopub.execute_input":"2024-08-14T04:55:41.012950Z","iopub.status.idle":"2024-08-14T04:56:09.302508Z","shell.execute_reply.started":"2024-08-14T04:55:41.012919Z","shell.execute_reply":"2024-08-14T04:56:09.301361Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-14 04:55:48.117513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-14 04:55:48.117640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-14 04:55:48.261901: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nNo model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8dae1f7cec04f34af18331c3d4cd380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db8bc945cae14fec84431ba909408ed6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dde62b5bfde453ea923a59e4e3b3dd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2cf91d7c8b840c5885b22db72d5d783"}},"metadata":{}},{"name":"stdout","text":"label: POSITIVE, with score: 0.9998\nlabel: NEGATIVE, with score: 0.5309\n","output_type":"stream"}]},{"cell_type":"markdown","source":"2 -  `automatic-speech-recognition` - Dataset as an Input","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, Audio\n\n# Or we can give it an entire dataset\n# Lets use automatic speech recognition\nspeech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n# Lets load the dataset\ndataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n# Make sure that the data set matches the sampling rate in which the model was trained\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))\n# Print the written audio\nresult = speech_recognizer(dataset[:4][\"audio\"])\nprint([d[\"text\"] for d in result])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:56:09.304809Z","iopub.execute_input":"2024-08-14T04:56:09.305478Z","iopub.status.idle":"2024-08-14T04:59:45.737133Z","shell.execute_reply.started":"2024-08-14T04:56:09.305430Z","shell.execute_reply":"2024-08-14T04:59:45.735926Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"883591a5d5e54a2382bdb4858a2e1305"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcd842bdd25d4f4b9f53a95afcad6eb8"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4db11f1d6064484a68893a9dcfc72d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"993d3a276b3641f590c3e8c4ed32ad89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4654895d8b5e4e31817c8baefab0ea1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"696edf7c991149809efe3a8a448d38d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4edcf65abdb491980059259f7090d6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5de0fd51348e46b7a7cb2c1f7522e4f8"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19660041d07e41a3a3a815527e9983af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f062415a1740e4bfd8c591fc378654"}},"metadata":{}},{"name":"stdout","text":"['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- 3: `multilingual-uncased-sentiment` - Selectring specific model and tokenizer in the pipeline\n\nUse `AutoModelForSequenceClassification` and `AutoTokenizer` to load the pretrained model and it's associated tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Select the model name\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\" # predicts the sentiment of the review as a number of stars (between 1 and 5).\n# Use AutoModelForSequenceClassification and AutoTokenizer from the named model\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n# Define the pipeline\nclassifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n# Run the pipeline\nclassifier(\"Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:59:45.738717Z","iopub.execute_input":"2024-08-14T04:59:45.739966Z","iopub.status.idle":"2024-08-14T05:00:00.292543Z","shell.execute_reply.started":"2024-08-14T04:59:45.739924Z","shell.execute_reply":"2024-08-14T05:00:00.291534Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"005df1bcec3c423a92a3dc866c6bc743"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d582d7c3b0144095baea02edb8bb7fd5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c030a2de25134e6ca04e37a1130cf90b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fd154e2f9c84ba0b8e949c9a1138038"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3d3bb6bea6d4013a119dc9ba316b34a"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[{'label': '5 stars', 'score': 0.7272652387619019}]"},"metadata":{}}]},{"cell_type":"markdown","source":"# AutoClass\nAutoClass is a shortcut that automatically retrieves the architecture of a pretrained model from its name or path","metadata":{}},{"cell_type":"markdown","source":"## Autotokenizer\n\nTokenizer is a dictionary that returns:\n\n- `input_ids`: numerical representations of your tokens.\n- `attention_mask`: indicates which tokens should be attended to.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nencoding = tokenizer(\"We are very happy to show you the 🤗 Transformers library.\")\n# The tokenizer returns a dictionary containing: input_ids & attention_mask\nprint(\"encoding -> input_ids: \", encoding[\"input_ids\"])\nprint(\"encoding -> attention_mask: \", encoding[\"attention_mask\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:00.294643Z","iopub.execute_input":"2024-08-14T05:00:00.294967Z","iopub.status.idle":"2024-08-14T05:00:00.774824Z","shell.execute_reply.started":"2024-08-14T05:00:00.294939Z","shell.execute_reply":"2024-08-14T05:00:00.773680Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"encoding -> input_ids:  [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102]\nencoding -> attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"# tokenizer can accept other inputs\npt_batch = tokenizer(\n    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n    padding=True,\n    truncation=True,\n    max_length=512,\n    return_tensors=\"pt\",\n)\nprint(\"pt_batch -> input_ids: \", pt_batch[\"input_ids\"])\nprint(\"pt_batch -> attention_mask: \", pt_batch[\"attention_mask\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:00.776390Z","iopub.execute_input":"2024-08-14T05:00:00.777287Z","iopub.status.idle":"2024-08-14T05:00:00.785271Z","shell.execute_reply.started":"2024-08-14T05:00:00.777247Z","shell.execute_reply":"2024-08-14T05:00:00.784208Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"pt_batch -> input_ids:  tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n         58263, 13299,   119,   102],\n        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n           102,     0,     0,     0]])\npt_batch -> attention_mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## AutoModel\nIt is important to select the desired [task](https://huggingface.co/docs/transformers/main/en/task_summary) of the model. The model outputs the final activations in the `logits` attribute, so by applying softmax function to the `logits` it is possible retrieve the probabilities","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom torch import nn\n\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\npt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n\n# Pass the preprocessed batch of inputs directly to the model by unpack the dictionary with **\npt_outputs = pt_model(**pt_batch)\n\npt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\nprint(pt_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:00.786485Z","iopub.execute_input":"2024-08-14T05:00:00.786996Z","iopub.status.idle":"2024-08-14T05:00:01.948152Z","shell.execute_reply.started":"2024-08-14T05:00:00.786968Z","shell.execute_reply":"2024-08-14T05:00:01.947116Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"All 🤗 Transformers models output the tensors before the final activation function (like softmax) because the final activation function is often fused with the loss.\n","metadata":{}},{"cell_type":"markdown","source":"## Save a Model\n\n1. `save_pretrained` to save the model","metadata":{}},{"cell_type":"code","source":"# Once the model is fine-tuned you can save it\npt_save_directory = \"./pt_save_pretrained\"\ntokenizer.save_pretrained(pt_save_directory)\npt_model.save_pretrained(pt_save_directory)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:01.949817Z","iopub.execute_input":"2024-08-14T05:00:01.950112Z","iopub.status.idle":"2024-08-14T05:00:03.106088Z","shell.execute_reply.started":"2024-08-14T05:00:01.950086Z","shell.execute_reply":"2024-08-14T05:00:03.104995Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"2. `from_pretrained` to load the model","metadata":{}},{"cell_type":"code","source":"# Then you can reload it\npt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:03.107329Z","iopub.execute_input":"2024-08-14T05:00:03.107663Z","iopub.status.idle":"2024-08-14T05:00:03.434981Z","shell.execute_reply.started":"2024-08-14T05:00:03.107635Z","shell.execute_reply":"2024-08-14T05:00:03.433566Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Custom Model Builds\nYou can modify the model's configuration class to change how a model is built\n\n1. `Autoconfig` to store the pretrained model config, and yoy select the attribute that you want to change ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoConfig\nmy_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:03.436759Z","iopub.execute_input":"2024-08-14T05:00:03.437195Z","iopub.status.idle":"2024-08-14T05:00:03.893622Z","shell.execute_reply.started":"2024-08-14T05:00:03.437153Z","shell.execute_reply":"2024-08-14T05:00:03.892639Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c5049e626d448dcbcacdc9d7cda50c6"}},"metadata":{}}]},{"cell_type":"markdown","source":"2. `AutoModel` to create a new model with the custom config","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel\nmy_model = AutoModel.from_config(my_config)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:03.897657Z","iopub.execute_input":"2024-08-14T05:00:03.898624Z","iopub.status.idle":"2024-08-14T05:00:05.255523Z","shell.execute_reply.started":"2024-08-14T05:00:03.898583Z","shell.execute_reply":"2024-08-14T05:00:05.254586Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Trainer (Pytorch)\n\n- All models are a standard `torch.nn.Module` so you can use them in any typical training loop \n- Transformers provides a [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) class for PyTorch\n     - Contains the basic training loop and adds additional functionality Idistributed training, mixed precision, etc)\n     - You can also write your own training loop","metadata":{}},{"cell_type":"markdown","source":"1.  **Model** (`PreTrainedModel` or `torch.nnModule`)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:05.256854Z","iopub.execute_input":"2024-08-14T05:00:05.257252Z","iopub.status.idle":"2024-08-14T05:00:10.402323Z","shell.execute_reply.started":"2024-08-14T05:00:05.257214Z","shell.execute_reply":"2024-08-14T05:00:10.400987Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d35a41f57524f1d9f57e47215c28913"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"2. **Training Arguments** (hyperparametes)","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(output_dir=\"path/to/save/folder/\",\n                                  learning_rate=2e-5,\n                                  per_device_train_batch_size=8,\n                                  per_device_eval_batch_size=8,\n                                  num_train_epochs=2,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:10.403879Z","iopub.execute_input":"2024-08-14T05:00:10.404216Z","iopub.status.idle":"2024-08-14T05:00:10.425270Z","shell.execute_reply.started":"2024-08-14T05:00:10.404189Z","shell.execute_reply":"2024-08-14T05:00:10.424081Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"3. **Preprocessing class** (tokenizer, image processor, feature extractor, or processor)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:10.426824Z","iopub.execute_input":"2024-08-14T05:00:10.427171Z","iopub.status.idle":"2024-08-14T05:00:12.735205Z","shell.execute_reply.started":"2024-08-14T05:00:10.427141Z","shell.execute_reply":"2024-08-14T05:00:12.733795Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"438bf2c53079431d94a84274f627de09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36cc7b3cd0944298899be987bc378be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"866042b371124a6983e90a8e0268acc8"}},"metadata":{}}]},{"cell_type":"markdown","source":"4. **Load a dataset**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:12.737432Z","iopub.execute_input":"2024-08-14T05:00:12.737846Z","iopub.status.idle":"2024-08-14T05:00:25.275003Z","shell.execute_reply.started":"2024-08-14T05:00:12.737805Z","shell.execute_reply":"2024-08-14T05:00:25.273534Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adbd2bd99f9f417fbb3ea4a8d51b4031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/699k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d5e9a4234834d05911980ce3b27c8f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/90.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef7210bb1e15460789bbfa1075b66d71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/92.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7f93e7a61b4402f9be52df40f773342"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9206ba09bfd24dbf84f52761bc1edae2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1ca18239894f169b01b0c7383b2e4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"414457a8613d41bda139d1ae6113ceee"}},"metadata":{}}]},{"cell_type":"markdown","source":"5. **Tokenize the dataset**","metadata":{}},{"cell_type":"code","source":"# Create a function to tokenize the dataset\ndef tokenize_dataset(dataset):\n    return tokenizer(dataset[\"text\"])\n\n# Apply it to the entire dataset\ndataset = dataset.map(tokenize_dataset, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:25.277336Z","iopub.execute_input":"2024-08-14T05:00:25.278474Z","iopub.status.idle":"2024-08-14T05:00:26.939335Z","shell.execute_reply.started":"2024-08-14T05:00:25.278414Z","shell.execute_reply":"2024-08-14T05:00:26.938009Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8530 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"052882dd330f439d85f5badb362cb3a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1066 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05222802d66d4574840b08f2a4d5816e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1066 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62a762610544427999606d5162c38720"}},"metadata":{}}]},{"cell_type":"markdown","source":"6 - **Data Collator with Padding** (to create a batch of examples from your dataset)","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:26.940976Z","iopub.execute_input":"2024-08-14T05:00:26.941989Z","iopub.status.idle":"2024-08-14T05:00:26.946919Z","shell.execute_reply.started":"2024-08-14T05:00:26.941946Z","shell.execute_reply":"2024-08-14T05:00:26.945827Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)  # doctest: +SKIP","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:26.948169Z","iopub.execute_input":"2024-08-14T05:00:26.948520Z","iopub.status.idle":"2024-08-14T05:00:27.722199Z","shell.execute_reply.started":"2024-08-14T05:00:26.948491Z","shell.execute_reply":"2024-08-14T05:00:27.721130Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T05:00:27.723478Z","iopub.execute_input":"2024-08-14T05:00:27.723786Z","iopub.status.idle":"2024-08-14T05:09:42.597725Z","shell.execute_reply.started":"2024-08-14T05:00:27.723760Z","shell.execute_reply":"2024-08-14T05:09:42.595972Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240814_050157-vtxlao83</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/juliandlb-pontificia-universidad-cat-lica-de-chile/huggingface/runs/vtxlao83' target=\"_blank\">path/to/save/folder/</a></strong> to <a href='https://wandb.ai/juliandlb-pontificia-universidad-cat-lica-de-chile/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/juliandlb-pontificia-universidad-cat-lica-de-chile/huggingface' target=\"_blank\">https://wandb.ai/juliandlb-pontificia-universidad-cat-lica-de-chile/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/juliandlb-pontificia-universidad-cat-lica-de-chile/huggingface/runs/vtxlao83' target=\"_blank\">https://wandb.ai/juliandlb-pontificia-universidad-cat-lica-de-chile/huggingface/runs/vtxlao83</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='383' max='2134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 383/2134 07:22 < 33:54, 0.86 it/s, Epoch 0.36/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3324\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3322\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3324\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2151\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2151\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}