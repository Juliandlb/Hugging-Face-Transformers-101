{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hugging Face Transformers 101\n\nThe objective of this notebook is to give an extensive summary on how to use the [transformers](https://github.com/huggingface/transformers) library from [Hugging Face](https://huggingface.co/).\n\n**Useful links:**\n- [Hugging Face - Model Hub](https://huggingface.co/models)\n- [Hugging Face - Datasets](https://huggingface.co/datasets)\n","metadata":{}},{"cell_type":"markdown","source":"# Pipelines\n\nThe [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines) is the easiest and fastest way to use a pretrained model for inference. In this case the pipeline downloads and caches a default pretrained model and tokenizer for sentiment analysis\n\n| **Task**                     | **Description**                                                                                              | **Modality**    | **Pipeline identifier**                       |\n|------------------------------|--------------------------------------------------------------------------------------------------------------|-----------------|-----------------------------------------------|\n| Text classification          | assign a label to a given sequence of text                                                                   | NLP             | pipeline(task=“sentiment-analysis”)           |\n| Text generation              | generate text given a prompt                                                                                 | NLP             | pipeline(task=“text-generation”)              |\n| Summarization                | generate a summary of a sequence of text or document                                                         | NLP             | pipeline(task=“summarization”)                |\n| Image classification         | assign a label to an image                                                                                   | Computer vision | pipeline(task=“image-classification”)         |\n| Image segmentation           | assign a label to each individual pixel of an image (supports semantic, panoptic, and instance segmentation) | Computer vision | pipeline(task=“image-segmentation”)           |\n| Object detection             | predict the bounding boxes and classes of objects in an image                                                | Computer vision | pipeline(task=“object-detection”)             |\n| Audio classification         | assign a label to some audio data                                                                            | Audio           | pipeline(task=“audio-classification”)         |\n| Automatic speech recognition | transcribe speech into text                                                                                  | Audio           | pipeline(task=“automatic-speech-recognition”) |\n| Visual question answering    | answer a question about the image, given an image and a question                                             | Multimodal      | pipeline(task=“vqa”)                          |\n| Document question answering  | answer a question about a document, given an image and a question                                            | Multimodal      | pipeline(task=\"document-question-answering\")  |\n| Image captioning             | generate a caption for a given image                                                                         | Multimodal      | pipeline(task=\"image-to-text\")                |\n","metadata":{}},{"cell_type":"markdown","source":"## Example 1: Sentiment Analysis - Vector as an Input","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# We can create a vector of data for the classifier\nclassifier = pipeline(\"sentiment-analysis\")\nprompts = [\"This is a very happy example :).\",\n           \"We hope you don't hate it.\"]\nresults = classifier(prompts)\nfor result in results:\n    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T02:07:41.806515Z","iopub.execute_input":"2024-08-14T02:07:41.807591Z","iopub.status.idle":"2024-08-14T02:07:42.223954Z","shell.execute_reply.started":"2024-08-14T02:07:41.807549Z","shell.execute_reply":"2024-08-14T02:07:42.222569Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"name":"stdout","text":"label: POSITIVE, with score: 0.9998\nlabel: NEGATIVE, with score: 0.5309\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Example 2: Automatic Speech Recognition - Dataset as an Input","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, Audio\n\n# Or we can give it an entire dataset\n# Lets use automatic speech recognition\nspeech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n# Lets load the dataset\ndataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n# Make sure that the data set matches the sampling rate in which the model was trained\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))\n# Print the written audio\nresult = speech_recognizer(dataset[:4][\"audio\"])\nprint([d[\"text\"] for d in result])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T02:02:21.535998Z","iopub.execute_input":"2024-08-14T02:02:21.536440Z","iopub.status.idle":"2024-08-14T02:03:13.983858Z","shell.execute_reply.started":"2024-08-14T02:02:21.536405Z","shell.execute_reply":"2024-08-14T02:03:13.982467Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a23d9bf08c8642da9f3d1af809cf2464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23d859316a0f4df5a6cc34da0ef063cb"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ec7b947b854c48a4d91c84ac35ac1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4214a17a634ea99a08388b04953c3c"}},"metadata":{}},{"name":"stdout","text":"['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Example 3: Sentiment Analysis - Selectring specific model and tokenizer\n\nUse `AutoModelForSequenceClassification` and `AutoTokenizer` to load the pretrained model and it's associated tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Select the model name\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n# Use AutoModelForSequenceClassification and AutoTokenizer from the named model\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n# Define the pipeline\nclassifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n# Run the pipeline\nclassifier(\"Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T02:29:26.068541Z","iopub.execute_input":"2024-08-14T02:29:26.071173Z","iopub.status.idle":"2024-08-14T02:29:28.150079Z","shell.execute_reply.started":"2024-08-14T02:29:26.071108Z","shell.execute_reply":"2024-08-14T02:29:28.148756Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[{'label': '5 stars', 'score': 0.7272652387619019}]"},"metadata":{}}]},{"cell_type":"markdown","source":"# AutoClass\nAutoClass is a shortcut that automatically retrieves the architecture of a pretrained model from its name or path","metadata":{}},{"cell_type":"markdown","source":"## Autotokenizer\n\nTokenizer is a dictionary that returns:\n\n- `input_ids`: numerical representations of your tokens.\n- `attention_mask`: indicates which tokens should be attended to.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nencoding = tokenizer(\"We are very happy to show you the 🤗 Transformers library.\")\n# The tokenizer returns a dictionary containing: input_ids & attention_mask\nprint(\"encoding -> input_ids: \", encoding[\"input_ids\"])\nprint(\"encoding -> attention_mask: \", encoding[\"attention_mask\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T02:55:11.118944Z","iopub.execute_input":"2024-08-14T02:55:11.119397Z","iopub.status.idle":"2024-08-14T02:55:11.552751Z","shell.execute_reply.started":"2024-08-14T02:55:11.119361Z","shell.execute_reply":"2024-08-14T02:55:11.551520Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"encoding -> input_ids:  [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102]\nencoding -> attention_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"# tokenizer can accept other inputs\npt_batch = tokenizer(\n    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n    padding=True,\n    truncation=True,\n    max_length=512,\n    return_tensors=\"pt\",\n)\nprint(\"pt_batch -> input_ids: \", pt_batch[\"input_ids\"])\nprint(\"pt_batch -> attention_mask: \", pt_batch[\"attention_mask\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T02:55:42.351012Z","iopub.execute_input":"2024-08-14T02:55:42.351455Z","iopub.status.idle":"2024-08-14T02:55:42.366380Z","shell.execute_reply.started":"2024-08-14T02:55:42.351418Z","shell.execute_reply":"2024-08-14T02:55:42.364760Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"pt_batch -> input_ids:  tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n         58263, 13299,   119,   102],\n        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n           102,     0,     0,     0]])\npt_batch -> attention_mask:  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## AutoModel\nIt is important to select the desired [task](https://huggingface.co/docs/transformers/main/en/task_summary) of the model. The model outputs the final activations in the `logits` attribute, so by applying softmax function to the `logits` it is possible retrieve the probabilities","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nfrom torch import nn\n\nmodel_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\npt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n\n# Pass the preprocessed batch of inputs directly to the model by unpack the dictionary with **\npt_outputs = pt_model(**pt_batch)\n\npt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\nprint(pt_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T03:06:35.549813Z","iopub.execute_input":"2024-08-14T03:06:35.550331Z","iopub.status.idle":"2024-08-14T03:06:37.056605Z","shell.execute_reply.started":"2024-08-14T03:06:35.550297Z","shell.execute_reply":"2024-08-14T03:06:37.055413Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"All 🤗 Transformers models output the tensors before the final activation function (like softmax) because the final activation function is often fused with the loss.\n","metadata":{}},{"cell_type":"markdown","source":"## Save a Model\n\n1 - `save_pretrained` to save the model","metadata":{}},{"cell_type":"code","source":"# Once the model is fine-tuned you can save it\npt_save_directory = \"./pt_save_pretrained\"\ntokenizer.save_pretrained(pt_save_directory)\npt_model.save_pretrained(pt_save_directory)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T03:19:26.234544Z","iopub.execute_input":"2024-08-14T03:19:26.234975Z","iopub.status.idle":"2024-08-14T03:19:27.771362Z","shell.execute_reply.started":"2024-08-14T03:19:26.234942Z","shell.execute_reply":"2024-08-14T03:19:27.770219Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"2 - `from_pretrained` to load the model","metadata":{}},{"cell_type":"code","source":"# Then you can reload it\npt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T03:19:27.773341Z","iopub.execute_input":"2024-08-14T03:19:27.773712Z","iopub.status.idle":"2024-08-14T03:19:28.169606Z","shell.execute_reply.started":"2024-08-14T03:19:27.773680Z","shell.execute_reply":"2024-08-14T03:19:28.168034Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Custom Model Builds\nYou can modify the model's configuration class to change how a model is built\n\n1 - `Autoconfig` to store the pretrained model config, and yoy select the attribute that you want to change ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoConfig\nmy_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:04:08.808637Z","iopub.execute_input":"2024-08-14T04:04:08.809741Z","iopub.status.idle":"2024-08-14T04:04:09.208804Z","shell.execute_reply.started":"2024-08-14T04:04:08.809697Z","shell.execute_reply":"2024-08-14T04:04:09.206979Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9beb7dfbdc404bb88e6a5b4c1b298313"}},"metadata":{}}]},{"cell_type":"markdown","source":"2 - `AutoModel` to create a new model with the custom config","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel\nmy_model = AutoModel.from_config(my_config)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T04:08:14.499975Z","iopub.execute_input":"2024-08-14T04:08:14.500909Z","iopub.status.idle":"2024-08-14T04:08:15.703041Z","shell.execute_reply.started":"2024-08-14T04:08:14.500830Z","shell.execute_reply":"2024-08-14T04:08:15.701750Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Trainer (Pytorch)\n\n- All models are a standard `torch.nn.Module` so you can use them in any typical training loop","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}